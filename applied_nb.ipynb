{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7989b-acfe-4ffa-bcb5-29c61237e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mutual_info_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "    \n",
    "from model_wrapper import NBWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b0d44-61b5-4856-ae0f-3fe92ed3040c",
   "metadata": {},
   "source": [
    "# Chapter 1: Data understanding and processing (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15df40-ae9a-4e22-90b3-6e9b256b8bcf",
   "metadata": {},
   "source": [
    "## 1.1 Get to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217b34e-940a-47c7-9e06-7f9615db6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./HR_comma_sep.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a042bff-4a07-41fe-933f-e0ca80dc356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0acf3-5d54-44fb-9110-e2d96590b8d0",
   "metadata": {},
   "source": [
    "Th dataset contains information about employees who worked in a company. These information included:\n",
    "- Satisfactory Level\n",
    "- Number of Project\n",
    "- Average Monthly Hours\n",
    "- Time Spend Company\n",
    "- Promotion Last 5 Years\n",
    "- Department\n",
    "- Salary\n",
    "\n",
    "The information was obtained mainly to predict employees retention - choose to stay or leave the company - defined by the \"left\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664290ba-f688-4555-be2c-80f29dd56015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4e509-578d-47df-ac55-595f6511b52b",
   "metadata": {},
   "source": [
    "## 1.2 Data cleaning and preprocessing\n",
    "Include handling with:\n",
    "- Inconsistent in col names\n",
    "- Missing values\n",
    "- Duplicate values\n",
    "- Identify target variable and features\n",
    "- Features importance and engineering\n",
    "- Outliers\n",
    "- Validation framework\n",
    "- Label encoding with One-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7c55b-dab4-4705-89b9-c3526ed089bb",
   "metadata": {},
   "source": [
    "### inconsistent column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2147ff2-044d-4b55-968a-2308fe18c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normailize cols name\n",
    "df.columns = df.columns.str.lower()\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2dcd1-cf1c-4fa6-b918-36e681df0205",
   "metadata": {},
   "source": [
    "### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bd061-b23f-4bcc-a4ea-0d60679be689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7523e-f903-45af-9a65-765e6cf486c0",
   "metadata": {},
   "source": [
    "$\\to$ Luckily, no missing values were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b53ff-7986-46b4-b617-a7f59cd01b35",
   "metadata": {},
   "source": [
    "### duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5557bb-5646-4903-b0ee-a152a78dc7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate values\n",
    "dups = df.duplicated().sum()\n",
    "print(dups/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc88a2c-1fb4-4a6a-8b98-4a2152bb74f6",
   "metadata": {},
   "source": [
    "$\\to$ 20% of the data were found to be duplicates. In this particular case, we will remove all the duplicates to prevent skewed, as each instances in the data represent an employee, and each of them should be treated independently for the best prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a1b4f-ddab-4404-9748-61a2eea2696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle duplication\n",
    "print(f\"Before: {df.shape}\")\n",
    "df = df.drop_duplicates(keep='first')\n",
    "print(f\"After: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104af895-52e2-46cf-a96c-1eb8ea678972",
   "metadata": {},
   "source": [
    "### obtain categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae3e69-db13-489c-bade-bf14a2f33bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get categorical features\n",
    "categorical = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "categorical.extend([\"work_accident\", \"promotion_last_5years\"])\n",
    "\n",
    "# get numerical features\n",
    "numerical = list(df.drop(columns=categorical).columns)\n",
    "numerical.remove(\"left\")\n",
    "\n",
    "print(categorical, numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d26db2-2f3e-4fd6-ab6d-9aa59a737f67",
   "metadata": {},
   "source": [
    "- Target is: 'left'\n",
    "- Categorical features include: 'department', 'salary', 'work_accident', 'promotion_last_5years'\n",
    "- Numerical features include: 'satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', 'time_spend_company'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97a247-46a5-4e47-b546-02bc1ae3e545",
   "metadata": {},
   "source": [
    "### imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0e4eed-b893-4d47-9519-d2096599574f",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = list(df.left.value_counts())\n",
    "\n",
    "plt.bar([\"Flase\", \"True\"], left)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21b1e5-fa00-4a30-bb18-d1f67b042cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: x/df.shape[0], df.left.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad52e1-bca6-4937-a31d-5610602de3e0",
   "metadata": {},
   "source": [
    "### feature importance and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9fe03-f8bf-437d-8a02-c5b4257a1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore categorical features with mutual info\n",
    "for col in categorical:\n",
    "    print(df[col].value_counts(), \"\\n\")\n",
    "    print(f\"Mutual info between retention and {col}: {mutual_info_score(df.left, df[col])}\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178b889-f96f-47a5-a6ad-cb5b294e5304",
   "metadata": {},
   "source": [
    "$\\to$ Based on the result of mutual information, it is likely that salary and work_accident are more of potential features to predict employee retention than the rest. Hence, we will include these in the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be087726-7eff-48bd-a3f2-5f62cf38e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore numerical features with correlation matrix\n",
    "df[numerical].corrwith(df.left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1b2a4-8978-4679-b050-f9fd637a326c",
   "metadata": {},
   "source": [
    "$\\to$ The correlation matrix tells us that, only features like satisfaction_level, time_spend_company, and average_monthly_hours are likely affected employee retention. Hence, we will also include them in the models, and save the others for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226a4aa-059b-4023-8fa4-daf4b7404644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features will be used in prediction\n",
    "categorical = [\"salary\", \"work_accident\"]\n",
    "numerical = [\"satisfaction_level\", \"time_spend_company\", \"average_montly_hours\"]\n",
    "target = \"left\"\n",
    "\n",
    "variables = categorical + numerical\n",
    "variables.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a770afe-198a-40d6-9512-fd8bad1f93b3",
   "metadata": {},
   "source": [
    "### outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a98ba-5e70-4e73-8c1a-37e5e8391524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers for numerical values\n",
    "plt.figure(figsize=(10, 15))\n",
    "for i, col in enumerate(numerical):\n",
    "    plt.subplot(5, 2, i + 1)\n",
    "    sns.boxplot(df, x=col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b6fdf-4f35-42da-a814-f3c8ad42ceb9",
   "metadata": {},
   "source": [
    "$\\to$ From the boxplots, we can observe that time_spend_company varible contains multiple outilers that need to be addressed. But before we can decide wheter or not to remove outliers, it is important to first investigate the reason behind the existence of these values. And since some models are more sensitive to outliers than other, it also depends on the type of models we choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8478b-0d3e-4ce3-9c36-5e4fb418d430",
   "metadata": {},
   "source": [
    "### validation framework\n",
    "Setting up a validation process includes:\n",
    "- Full Train data (80%) use for cross validation\n",
    "- Test data (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df6c11-aa93-4358-92c5-f9ca17287f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data\n",
    "df_full_train, df_test = train_test_split(df[variables], test_size=0.2, random_state=1)\n",
    "len(df_full_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62601c3-0728-481b-b715-b69937bb4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc722e-1a61-4114-8e7f-d52194651b87",
   "metadata": {},
   "source": [
    "# Chapter 2: Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c37f99-442f-4e3a-b9a6-61bf38ad03dd",
   "metadata": {},
   "source": [
    "## 2.1 Obtain features and target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b22c5-766f-4aa9-8846-9d1e3fc9e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(data):\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target].values\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = getXy(df_full_train)\n",
    "X_test, y_test = getXy(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea4436-68a1-461c-a1b3-206247bc2eaa",
   "metadata": {},
   "source": [
    "## 2.2 Train NB variants with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fee9b6-b010-4d35-8927-a0d6e5c13289",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_variants = {\n",
    "    'gaussian': GaussianNB(),\n",
    "    'multinomial': MultinomialNB(),\n",
    "    'bernoulli': BernoulliNB()\n",
    "}\n",
    "\n",
    "# init multiple models at a time\n",
    "for name, model in nb_variants.items():\n",
    "    nb_variants[name] = NBWrapper(model=model, target=target,\n",
    "                                  num=numerical, cat=categorical)\n",
    "\n",
    "# apply cross-validate for each model\n",
    "for name, wrapper in nb_variants.items():\n",
    "    score = wrapper.cross_validate(X_train, y_train)\n",
    "    print(f\"{name.capitalize()}: roc_auc_score = {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80bc88-6131-4bfa-bfac-9804e143cceb",
   "metadata": {},
   "source": [
    "# Chapter 3: Fine-tuning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e766e85-2395-4307-bb28-ce7c73ea376e",
   "metadata": {},
   "source": [
    "## 3.1 Tune with predefined hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f0a60-a36b-4f89-818a-6e1954a4a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gaussian': {\n",
    "        'classifier__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "    },\n",
    "    'multinomial': {\n",
    "        'classifier__alpha': [0.1, 0.5, 1.0, 1.5, 2.0], \n",
    "        'classifier__fit_prior': [True, False]\n",
    "    },\n",
    "    'bernoulli': {\n",
    "        'classifier__alpha': [0.1, 0.5, 1.0, 1.5, 2.0],\n",
    "        'classifier__binarize': [0.0, 0.5, 1.0],\n",
    "        'classifier__fit_prior': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "for name, wrapper in nb_variants.items():\n",
    "    best_params = wrapper.grid_search(X=X_train, y=y_train, param_grid=params[name])\n",
    "    print(f\"Best Parameters for {name.capitalize()}: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d784c75-517f-4fe9-823f-fcfed814f63a",
   "metadata": {},
   "source": [
    "## 3.2 Retrain with new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b8107c-e141-4b12-ace1-17c721d6a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_variants = {\n",
    "    'gaussian': GaussianNB(var_smoothing=1e-06),\n",
    "    'multinomial': MultinomialNB(alpha=0.1, fit_prior=True),\n",
    "    'bernoulli': BernoulliNB(alpha=0.1, binarize=0.5, fit_prior=True)\n",
    "}\n",
    "\n",
    "# init multiple models at a time\n",
    "for name, model in nb_variants.items():\n",
    "    nb_variants[name] = NBWrapper(model=model, target=target,\n",
    "                                  num=numerical, cat=categorical)\n",
    "\n",
    "# apply cross-validate for each model\n",
    "train_score = {}\n",
    "for name, wrapper in nb_variants.items():\n",
    "    train_score[name] = wrapper.cross_validate(X_train, y_train)\n",
    "    print(f\"{name.capitalize()}: roc_auc_score = {train_score[name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb1d46-c996-49e0-a571-29b0bb88508b",
   "metadata": {},
   "source": [
    "## 3.3 Test with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebdff4-6e38-4240-ba21-479d49e64b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model and test with test dataset\n",
    "cm = {}\n",
    "test_score = {}\n",
    "for name, wrapper in nb_variants.items():\n",
    "    model = wrapper.model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    cm[name] = confusion_matrix(y_test, y_pred)\n",
    "    test_score[name] = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"{name.capitalize()}: roc_auc_score = {test_score[name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52faf6ce-dd74-450c-96e7-bd7dc293935e",
   "metadata": {},
   "source": [
    "# Chapter 4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81763b94-20f8-49a7-a759-e1a270538678",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gaussian', 'multinomial', 'bernoulli']\n",
    "scores = {\n",
    "    'train': (0.82, 0.77, 0.79),\n",
    "    'test': (0.74, 0.5, 0.64)\n",
    "}\n",
    "\n",
    "# create dataframe to suite with seaborn barplot\n",
    "data = []\n",
    "for model, train, test in zip(models, scores['train'], scores['test']):\n",
    "    data.append({'Model': model, 'Dataset': 'Train', 'ROC-AUC score': train})\n",
    "    data.append({'Model': model, 'Dataset': 'Test', 'ROC-AUC score': test})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# plot the data\n",
    "ax = sns.barplot(data=df, x='Model', y='ROC-AUC score', hue='Dataset', errorbar=None)\n",
    "ax.bar_label(ax.containers[0], fontsize=10)\n",
    "ax.bar_label(ax.containers[1], fontsize=10)\n",
    "plt.title('Model Performance on Train and Test Datasets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507fb082-248b-4edc-b82a-3ca95844eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (name, matrix) in enumerate(cm.items()):\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', ax=axes[i])\n",
    "    axes[i].set_title(f\"{name.capitalize()}\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
